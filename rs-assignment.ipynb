{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting MovieLens data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
    "\n",
    "* Upload ml-100k.zip\n",
    "\n",
    "* Extract using the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ml-100k.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIELENS_DIR = \"ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mREADME\u001b[m\u001b[m       \u001b[31mu.genre\u001b[m\u001b[m      \u001b[31mu.user\u001b[m\u001b[m       \u001b[31mu2.test\u001b[m\u001b[m      \u001b[31mu4.test\u001b[m\u001b[m      \u001b[31mua.test\u001b[m\u001b[m\r\n",
      "\u001b[31mallbut.pl\u001b[m\u001b[m    \u001b[31mu.info\u001b[m\u001b[m       \u001b[31mu1.base\u001b[m\u001b[m      \u001b[31mu3.base\u001b[m\u001b[m      \u001b[31mu5.base\u001b[m\u001b[m      \u001b[31mub.base\u001b[m\u001b[m\r\n",
      "\u001b[31mmku.sh\u001b[m\u001b[m       \u001b[31mu.item\u001b[m\u001b[m       \u001b[31mu1.test\u001b[m\u001b[m      \u001b[31mu3.test\u001b[m\u001b[m      \u001b[31mu5.test\u001b[m\u001b[m      \u001b[31mub.test\u001b[m\u001b[m\r\n",
      "\u001b[31mu.data\u001b[m\u001b[m       \u001b[31mu.occupation\u001b[m\u001b[m \u001b[31mu2.base\u001b[m\u001b[m      \u001b[31mu4.base\u001b[m\u001b[m      \u001b[31mua.base\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls {MOVIELENS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(folder_path, file_name):\n",
    "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = getData(MOVIELENS_DIR, 'u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of users:', 943)\n",
      "('Number of items:', 1682)\n"
     ]
    }
   ],
   "source": [
    "num_users = len(rating_df.userID.unique())\n",
    "num_items = len(rating_df.itemID.unique())\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
    "    for(index,userID,itemID,rating,timestamp) in rating_df.itertuples():\n",
    "        matrix[userID-1, itemID-1] = rating\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 4, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPreprocessor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLineRecSys(object):\n",
    "    def __init__(self, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            method: string. From ['popularity','useraverage']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.method_name\n",
    "        \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'popularity': self.popularity,\n",
    "            'useraverage': self.useraverage,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def useraverage(train_matrix, num_users, num_items):\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "            # Extract the items the user already rated\n",
    "            userVector = train_matrix[user, :]\n",
    "            ratedItems = userVector[userVector.nonzero()]\n",
    "            \n",
    "            #If not empty, calculate average and set as rating for the current item\n",
    "            if ratedItems.size == 0:\n",
    "                itemAvg = 0\n",
    "            else:\n",
    "                itemAvg = ratedItems.mean()\n",
    "            predictionMatrix[user, item] = itemAvg\n",
    "            \n",
    "            # report progress every 100 users\n",
    "            if (user % 100 == 0 and item == 1):\n",
    "                print (\"calculated %d users\" % (user,))\n",
    "\n",
    "        return predictionMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def popularity(train_matrix, num_users, num_items):\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    \n",
    "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "        itemPopularity = np.zeros((num_items))\n",
    "        for item in range(num_items):\n",
    "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
    "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
    "            if numOfUsersRated == 0:\n",
    "                itemPopularity[item] = 0\n",
    "            else:\n",
    "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "    \n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            predictionMatrix[user, item] = itemPopularity[item]\n",
    "            \n",
    "            # report progress every 100 users\n",
    "            if (user % 100 == 0 and item == 1):\n",
    "                print (\"calculated %d users\" % (user,))\n",
    "\n",
    "\n",
    "        return predictionMatrix    \n",
    "    \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        self.__model = self.method(train_matrix, num_users, num_items)\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "            \n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You don not have model..\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_recsys = BaseLineRecSys('popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "popularity_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = popularity_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(x<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:05, 1521.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  popularity\n",
       "0     196     242       3  881250949         0.0\n",
       "1     186     302       3  891717742         0.0\n",
       "2      22     377       1  878887116         0.0\n",
       "3     244      51       2  880606923         0.0\n",
       "4     166     346       1  886397596         0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_user_rating_recsys = BaseLineRecSys('useraverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.61029412, 3.61029412, 3.61029412, ..., 3.61029412, 3.61029412,\n",
       "        3.61029412],\n",
       "       [3.70967742, 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
       "        3.70967742],\n",
       "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
       "        2.7962963 ],\n",
       "       ...,\n",
       "       [4.04545455, 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
       "        4.04545455],\n",
       "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
       "        4.26582278],\n",
       "       [3.41071429, 3.41071429, 3.41071429, ..., 3.41071429, 3.41071429,\n",
       "        3.41071429]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:04, 1552.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>useraverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.413043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>3.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.651261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  useraverage\n",
       "0     196     242       3  881250949     3.615385\n",
       "1     186     302       3  891717742     3.413043\n",
       "2      22     377       1  878887116     3.351562\n",
       "3     244      51       2  880606923     3.651261\n",
       "4     166     346       1  886397596     3.550000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimBasedRecSys(object):\n",
    "\n",
    "    def __init__(self, base, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
    "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.base = base\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.base+'-'+self.method_name\n",
    "    \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'cosine': self.cosine,\n",
    "            'euclidean': self.euclidean,\n",
    "            'somethingelse': self.somethingelse,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine(matrix):\n",
    "        \"\"\"\n",
    "            cosine similarity\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean(matrix):\n",
    "        \"\"\"\n",
    "            euclidean similarity\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1/(1 + pairwise_distances(matrix, metric='euclidean')) \n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def somethingelse(matrix):\n",
    "        \"\"\" \n",
    "        manhattan? or super-natural intuition similarity\n",
    "           \n",
    "        \"\"\" \n",
    "        similarity_matrix = 1/(1 + pairwise_distances(matrix, metric='manhattan'))\n",
    "     \n",
    "        return similarity_matrix\n",
    "        \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_row: scalar. number of users\n",
    "                num_col: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method assigns the result to self.model\n",
    "            \n",
    "            NOTES:\n",
    "                self.__model should contain predictions for *all* user and items\n",
    "                (don't worry about predicting for observed (user,item) pairs,\n",
    "                 since we won't be using these predictions in the evaluation)\n",
    "                (see code in for an efficient vectorized example)\n",
    "        \"\"\"\n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        \n",
    "        if self.base == 'user':\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            uu_similarity = self.method(train_matrix)\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
    "    \n",
    "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "            self.__model = predictionMatrix\n",
    "            \n",
    "        elif self.base == 'item':\n",
    "            train_matrix = train_matrix.T\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            ii_similarity = self.method(train_matrix)\n",
    "            normalizer = np.matmul(ii_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(ii_similarity, train_matrix)/normalizer\n",
    "\n",
    "            itemaverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
    "            self.__model = predictionMatrix.T\n",
    "        else:\n",
    "            print('No other option available')\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "            NOTE: 1. data can have more columns, but your function should ignore \n",
    "                  additional columns.\n",
    "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
    "                  if base == 'user' and method == 'cosine', \n",
    "                  then base-method == 'user-cosine'\n",
    "                  3. your predictions go to 'base-method' column\n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You do not have model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of how to call similarity functions.\n",
    "I = np.eye(3)\n",
    "SimBasedRecSys.cosine(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.41421356, 0.41421356],\n",
       "       [0.41421356, 1.        , 0.41421356],\n",
       "       [0.41421356, 0.41421356, 1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.euclidean(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 0.33333333],\n",
       "       [0.33333333, 1.        , 0.33333333],\n",
       "       [0.33333333, 0.33333333, 1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.somethingelse(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity works better because euclidean distance is large for vectors of different lengths. If two users have similar likes and tend to watch similar movies but one is tend to give higher ratings than another. Euclidean distance is large for that situation but actually their similarity is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the reasons for using Euclidean and/or Manhattan distance is the relative ease of their implementation. If you want to place less emphasis on outliers, manhattan distance will try to reduce all errors equally since the gradient has constant magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       ...,\n",
       "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:05, 1517.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>4.025213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>4.142828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>1.922080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.431884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.424963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  user-cosine\n",
       "0     196     242       3  881250949     4.025213\n",
       "1     186     302       3  891717742     4.142828\n",
       "2      22     377       1  878887116     1.922080\n",
       "3     244      51       2  880606923     3.431884\n",
       "4     166     346       1  886397596     3.424963"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.75429099, 3.66419957, 3.73222997, ..., 3.60248287, 3.79662696,\n",
       "        3.90232044],\n",
       "       [3.83658867, 3.80424519, 3.77473905, ..., 3.72798332, 3.9109779 ,\n",
       "        3.79775927],\n",
       "       [2.84492718, 2.89389328, 2.84327324, ..., 2.99504451, 3.16444153,\n",
       "        2.9858119 ],\n",
       "       ...,\n",
       "       [4.11427954, 4.0558267 , 4.00963139, ..., 4.        , 3.87872799,\n",
       "        4.14814803],\n",
       "       [4.37096823, 4.39679254, 4.33543016, ..., 3.955358  , 4.41891089,\n",
       "        4.57995134],\n",
       "       [3.52030345, 3.46948821, 3.52393064, ..., 0.        , 3.6110641 ,\n",
       "        3.59656861]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "item_cosine_recsys.predict_all(rating_df, num_users, num_items)\n",
    "item_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:03, 1578.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.591314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.344077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2.965365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.637332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.333013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  item-cosine\n",
       "0     196     242       3  881250949     3.591314\n",
       "1     186     302       3  891717742     3.344077\n",
       "2      22     377       1  878887116     2.965365\n",
       "3     244      51       2  880606923     3.637332\n",
       "4     166     346       1  886397596     3.333013"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class getRecommender(object):\n",
    "\n",
    "    def __init__(self, Y, R, num_users, num_items, params=None, n=10, theLambda=10, maxIter=200):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y - 用户对影片的评分矩阵\n",
    "            R - 用户j是否对影片i评分的矩阵 (0/1)\n",
    "            params - 若有初始化参数，可在此传入(Theta, X)\n",
    "            n - 电影的特征数\n",
    "            theLambda - 正则化参数\n",
    "            maxIter - 最大迭代次数\n",
    "        Returns:\n",
    "            train - 训练函数\n",
    "            predict - 预测函数\n",
    "            getTopRecommends - 获取特定影片的最相似推荐\n",
    "        \"\"\"\n",
    "        self.Y = Y\n",
    "        self.R = R\n",
    "        self.params = params\n",
    "        self.n = n\n",
    "        self.theLambda = theLambda\n",
    "        self.maxIter = maxIter\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.modified_Y = self.avg_score()[0]\n",
    "        self.mu = self.avg_score()[1]\n",
    "        \n",
    "    def avg_score(self):\n",
    "\n",
    "        # 标准化影片的评分\n",
    "        mu = np.zeros((self.num_items, 1), dtype=np.float)\n",
    "        for i in range(self.num_items):\n",
    "            totalRates = np.sum(self.Y[i])\n",
    "            validCount = len(np.nonzero(self.R[i])[0])\n",
    "            mu[i] = totalRates / validCount\n",
    "        modified_Y = self.Y - mu\n",
    "        return modified_Y,mu\n",
    "\n",
    "    def roll(self, Theta, X):\n",
    "        \"\"\"\n",
    "        对于模型而言，Theta和X都是待学习的参数，需要放在一起直接优化\n",
    "        Args:\n",
    "            Theta - 用户偏好矩阵\n",
    "            X - 电影特征矩阵\n",
    "        Returns:\n",
    "            vector - 折叠后的参数\n",
    "        在numpy中矩阵我们十分常用，但有时候我们会将矩阵转化为数组，\n",
    "        方法很简单，直接在矩阵名后加 .A 即可。\n",
    "        \"\"\"\n",
    "\n",
    "        #return np.hstack((X.A.T.flatten(), Theta.A.T.flatten()))\n",
    "        return np.hstack((X.A.T.flatten(), Theta.A.T.flatten()))\n",
    "\n",
    "    def unroll(self,vector):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vector 参数向量\n",
    "        Returns:\n",
    "            Theta - 用户偏好矩阵\n",
    "            X - 电影特征矩阵\n",
    "        \"\"\"\n",
    "        X = np.mat(vector[:self.num_items * self.n].reshape(self.n, self.num_items).T)\n",
    "        Theta = np.mat(vector[self.num_items * self.n:].reshape(self.n, self.num_users).T)\n",
    "        return Theta, X\n",
    "\n",
    "    def initParams(self):\n",
    "        \"\"\"初始化参数\n",
    "\n",
    "        Returns:\n",
    "            Theta - 用户偏好矩阵\n",
    "            X - 电影特征矩阵\n",
    "        \"\"\"\n",
    "        Theta = np.mat(np.random.rand(self.num_users, self.n))\n",
    "        X = np.mat(np.random.rand(self.num_items, self.n))\n",
    "        return Theta, X\n",
    "\n",
    "    def regularize(self,param):\n",
    "        \"\"\"对参数进行正则化\n",
    "        Args:\n",
    "            param - 参数\n",
    "        Return:\n",
    "            regParam - 正规化后的参数\n",
    "        \"\"\"\n",
    "        return self.theLambda * 0.5 * np.sum(np.power(param, 2))\n",
    "\n",
    "    def J(self, params):\n",
    "        \"\"\"代价函数\n",
    "\n",
    "        Args:\n",
    "            params - 参数向量\n",
    "            nu - 用户数\n",
    "            nm - 电影数\n",
    "            n - 特征数\n",
    "        Return:\n",
    "            J - 预测代价\n",
    "        \"\"\"\n",
    "        # 参数展开\n",
    "        Theta, X = self.unroll(params)\n",
    "        # 计算误差\n",
    "        rows, cols = np.nonzero(self.R)\n",
    "        # 预测\n",
    "        h = self.predict(Theta, X)\n",
    "        self.avg_score()\n",
    "        diff = h - self.modified_Y\n",
    "        diff[self.R != 1] = 0\n",
    "        error = 0.5 * np.sum(np.power(diff, 2))\n",
    "        \n",
    "        #  正则化 Theta\n",
    "        regTheta = self.regularize(Theta)\n",
    "        #  正规化 x\n",
    "        regX = self.regularize(X)\n",
    "        \n",
    "        return error + regTheta + regX\n",
    "\n",
    "    def gradient(self, params):\n",
    "        \"\"\"计算梯度\n",
    "\n",
    "        Args:\n",
    "            params - 参数向量\n",
    "        Returns:\n",
    "            grad - 梯度向量\n",
    "        \"\"\"\n",
    "        Theta, X = self.unroll(params)\n",
    "        \n",
    "        # 当前梯度初始化成0\n",
    "        ThetaGrad = np.mat(np.zeros(Theta.shape))\n",
    "        XGrad = np.mat(np.zeros(X.shape))\n",
    "        \n",
    "        error = self.predict(Theta, X) - self.modified_Y\n",
    "        error[self.R != 1] = 0\n",
    "        \n",
    "        # 这里只需要计算梯度\n",
    "        ThetaGrad = error.T * X + self.theLambda * Theta\n",
    "        XGrad =  error * Theta + self.theLambda * X\n",
    "        \n",
    "        return self.roll(ThetaGrad, XGrad)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"训练\n",
    "\n",
    "        Returns:\n",
    "            Theta - 用户偏好矩阵\n",
    "            X - 电影特征矩阵\n",
    "        \"\"\"\n",
    "        # 初始化参数\n",
    "        if not self.params:\n",
    "            Theta, X = self.initParams()\n",
    "        else:\n",
    "            Theta = self.params['Theta']\n",
    "            X = self.params['X']\n",
    "            \n",
    "        # 最小化目标函数\n",
    "        res = minimize(self.J, x0=self.roll(Theta, X), jac=self.gradient,\n",
    "                       method='CG', options={'disp': True, 'maxiter': self.maxIter})\n",
    "        Theta, X = self.unroll(res.x)\n",
    "        return Theta, X\n",
    "\n",
    "    def predict(self, Theta, X):\n",
    "        \"\"\"预测\n",
    "        Args:\n",
    "            Theta - 用户偏好矩阵\n",
    "            X - 电影特征矩阵\n",
    "        Return:\n",
    "            h 预测\n",
    "        \"\"\"\n",
    "        return X * Theta.T + self.mu\n",
    "\n",
    "    def getTopRecommends(self, Theta, X, i, count, rated, items):\n",
    "        \"\"\"获得推荐\n",
    "\n",
    "        Args:\n",
    "            Theta - 用户偏好矩阵\n",
    "            X - 影片特征矩阵\n",
    "            i - 用户索引\n",
    "            count - 目标推荐数量\n",
    "            rated - 已经评价的影片id\n",
    "            items - 影片库\n",
    "        Returns:\n",
    "            topRecommends - 推荐项目\n",
    "        \"\"\"\n",
    "        predictions = self.predict(Theta, X)[:, i]\n",
    "        \n",
    "        # 实用pandas的DataFrame可以将不同类型数据放在一个Frame中，方便排序等操作\n",
    "        # 相较而言，numpy的多维数组要求内部类型完全一致\n",
    "        df = pd.DataFrame(data=predictions, columns=['prediction',])\n",
    "        df['movie'] = items\n",
    "        df.sort_values(by='prediction', ascending=False,inplace=True)\n",
    "        # 不推荐已经评过分的影片\n",
    "        df.drop(rated, inplace=True)\n",
    "        \n",
    "        return df[0:count]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我的评分:\n",
      "Toy Story (1995)                                   4.0\n",
      "Twelve Monkeys (1995)                              3.0\n",
      "Usual Suspects, The (1995)                         5.0\n",
      "Outbreak (1995)                                    4.0\n",
      "Shawshank Redemption, The (1994)                   5.0\n",
      "While You Were Sleeping (1995)                     3.0\n",
      "Forrest Gump (1994)                                5.0\n",
      "Silence of the Lambs, The (1991)                   2.0\n",
      "Alien (1979)                                       4.0\n",
      "Die Hard 2 (1990)                                  5.0\n",
      "Sphere (1998)                                      5.0\n"
     ]
    }
   ],
   "source": [
    "def getMovie(line):\n",
    "    return ' '.join(line.split()[1:])\n",
    "movieList = []\n",
    "with open('movie_ids.txt') as f:\n",
    "    for line in f:\n",
    "        movieList.append(getMovie(line.strip()))\n",
    "\n",
    "\n",
    "myRatings = np.mat(np.zeros((num_items,1)))\n",
    "\n",
    "myRatings[0] = 4\n",
    "myRatings[97] = 2\n",
    "myRatings[6] = 3\n",
    "myRatings[11] = 5\n",
    "myRatings[53] = 4\n",
    "myRatings[63] = 5\n",
    "myRatings[65] = 3\n",
    "myRatings[68] = 5\n",
    "myRatings[182] = 4\n",
    "myRatings[225] = 5\n",
    "myRatings[354] = 5\n",
    "\n",
    "#u:表示unicode字符串,不是仅仅是针对中文, 可以针对任何的字符串，代表是对字符串进行unicode编码。\n",
    "#一般英文字符在使用各种编码下, 基本都可以正常解析, 所以一般不带u；但是中文, 必须表明所需编码, 否则一旦编码转换就会出现乱码。 \n",
    "print u'我的评分:' \n",
    "for i in range(num_items):\n",
    "    if myRatings[i] > 0:\n",
    "        print u'{:<50} {}'.format( movieList[i], myRatings[i].A[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataPreprocessor(rating_df, num_users, num_items).T\n",
    "R = Y.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将我们的新用户数据加入\n",
    "Y = np.column_stack((myRatings, Y))\n",
    "R = np.column_stack((myRatings, R)).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "getrecommender = getRecommender(Y, R, num_users+1, num_items, params=None, n=10, theLambda=10, maxIter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 70968.832386\n",
      "         Iterations: 200\n",
      "         Function evaluations: 311\n",
      "         Gradient evaluations: 311\n"
     ]
    }
   ],
   "source": [
    "Theta, X = getrecommender.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[-1.10885202,  0.38094358,  0.129931  , ..., -0.25798043,\n",
       "          -0.21183504, -0.2061962 ],\n",
       "         [-1.82382714,  0.01306154,  0.36601534, ..., -0.37173746,\n",
       "           0.24441562, -0.87837661],\n",
       "         [-1.30406501,  0.53997951, -0.08879527, ..., -0.38387081,\n",
       "           0.23903291, -0.4241149 ],\n",
       "         ...,\n",
       "         [-1.21119946,  0.36238515,  0.09667597, ..., -0.14064922,\n",
       "          -0.00585555, -0.27742836],\n",
       "         [-1.16097862,  0.42901331, -0.00283875, ..., -0.15580987,\n",
       "          -0.29222477, -0.33623251],\n",
       "         [-1.05293276,  0.14498352, -0.90040723, ..., -0.67060729,\n",
       "          -0.60220509, -1.34489184]]),\n",
       " matrix([[ 1.39092671, -1.19340605, -0.2918934 , ...,  1.21438619,\n",
       "          -0.531735  ,  0.38708774],\n",
       "         [ 1.14232337, -0.33510632, -0.03068044, ...,  0.86386161,\n",
       "          -0.03846268,  0.48863585],\n",
       "         [ 0.96992771, -0.42316791,  0.14617324, ...,  0.07198875,\n",
       "           0.13878048,  0.61932611],\n",
       "         ...,\n",
       "         [ 0.1670256 ,  0.00393945,  0.07168983, ...,  0.11902605,\n",
       "          -0.06631176,  0.13911235],\n",
       "         [ 0.26865623,  0.05346598,  0.03467467, ...,  0.00382906,\n",
       "          -0.08966472,  0.25928504],\n",
       "         [ 0.36033432,  0.02470459,  0.0313808 , ...,  0.14851977,\n",
       "           0.0260413 ,  0.18290931]]))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>4.667510</td>\n",
       "      <td>Great Day in Harlem, A (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>4.198986</td>\n",
       "      <td>Someone Else's America (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>3.853336</td>\n",
       "      <td>Aiqing wansui (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>3.819708</td>\n",
       "      <td>Entertaining Angels: The Dorothy Day Story (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>3.703305</td>\n",
       "      <td>Marlene Dietrich: Shadow and Light (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>3.653813</td>\n",
       "      <td>They Made Me a Criminal (1939)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>3.594069</td>\n",
       "      <td>Santa with Muscles (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>3.385853</td>\n",
       "      <td>Window to Paris (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>3.385801</td>\n",
       "      <td>Farmer &amp; Chase (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>3.316223</td>\n",
       "      <td>Tokyo Fist (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction                                              movie\n",
       "813     4.667510                      Great Day in Harlem, A (1994)\n",
       "1598    4.198986                      Someone Else's America (1995)\n",
       "1535    3.853336                               Aiqing wansui (1994)\n",
       "1652    3.819708  Entertaining Angels: The Dorothy Day Story (1996)\n",
       "1200    3.703305          Marlene Dietrich: Shadow and Light (1996)\n",
       "1121    3.653813                     They Made Me a Criminal (1939)\n",
       "1499    3.594069                          Santa with Muscles (1996)\n",
       "1491    3.385853                             Window to Paris (1994)\n",
       "1497    3.385801                              Farmer & Chase (1995)\n",
       "1612    3.316223                                  Tokyo Fist (1995)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rated = np.nonzero(myRatings)[0].tolist()\n",
    "# -1 就是我们刚才加入的最新用户\n",
    "topRecommends = getrecommender.getTopRecommends(Theta, X, -1, 10, rated, movieList)\n",
    "topRecommends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidation(object):\n",
    "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(MOVIELENS_DIR)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:12, 1565.64it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:12, 1628.29it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:11, 1705.33it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:11, 1700.61it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:11, 1698.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:11, 1720.05it/s]\n",
      "20000it [00:11, 1674.60it/s]\n",
      "20000it [00:11, 1699.18it/s]\n",
      "20000it [00:11, 1685.97it/s]\n",
      "20000it [00:11, 1700.00it/s]\n"
     ]
    }
   ],
   "source": [
    "algorithm_instances = [item_cosine_recsys, \n",
    "                       user_cosine_recsys]\n",
    "cv_RMSE = CrossValidation('RMSE')\n",
    "results = cv_RMSE.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average and 95% confidence interval of RMSE results for item-cosine is : [1.020082900106248, [1.0068242686250732, 1.0333415315874226]]\n",
      "The average and 95% confidence interval of RMSE results for user-cosine is : [1.0173541216605808, [1.009013080226148, 1.0256951630950135]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The average and 95% confidence interval of RMSE results for item-cosine is : [{}, {}]\".format(results['item-cosine'][1],results['item-cosine'][2:4]))\n",
    "print(\"The average and 95% confidence interval of RMSE results for user-cosine is : [{}, {}]\".format(results['user-cosine'][1],results['user-cosine'][2:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of ratings per user is larger than the average number of ratings per item so for item based collaborative filtering it is more difficult to find similar items than user based which would reduce accuracy of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1572.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1617.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1613.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1653.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1592.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1627.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1645.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1639.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1536.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1633.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:12, 1654.59it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:12, 1632.89it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:12, 1630.76it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:12, 1545.10it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:12, 1630.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1630.83it/s]\n",
      "20000it [00:12, 1628.09it/s]\n",
      "20000it [00:12, 1588.63it/s]\n",
      "20000it [00:12, 1650.63it/s]\n",
      "20000it [00:13, 1538.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1491.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1594.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1523.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:12, 1552.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:15, 1251.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:15, 1258.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:16, 1227.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1346.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1397.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:19, 1041.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:16, 1242.15it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:17, 1136.36it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:16, 1215.09it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:15, 1305.52it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:16, 1221.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:17, 1137.44it/s]\n",
      "20000it [00:17, 1175.86it/s]\n",
      "20000it [00:17, 1126.14it/s]\n",
      "20000it [00:16, 1202.04it/s]\n",
      "20000it [00:14, 1341.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1383.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:15, 1328.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:16, 1240.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:16, 1230.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:15, 1310.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1374.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1378.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1356.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:15, 1329.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:15, 1330.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:16, 1207.69it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:15, 1263.93it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:15, 1275.23it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:15, 1294.90it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:15, 1328.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:16, 1231.61it/s]\n",
      "20000it [00:16, 1223.11it/s]\n",
      "20000it [00:15, 1328.62it/s]\n",
      "20000it [00:14, 1357.07it/s]\n",
      "20000it [00:14, 1343.78it/s]\n"
     ]
    }
   ],
   "source": [
    "algorithm_instances = [popularity_recsys,\n",
    "                       average_user_rating_recsys,\n",
    "                       item_cosine_recsys, \n",
    "                       user_cosine_recsys]\n",
    "cv_RMSE = CrossValidation('RMSE')\n",
    "cv_patk = CrossValidation('P@K')\n",
    "cv_ratk = CrossValidation('R@K')\n",
    "results_RMSE = cv_RMSE.run(algorithm_instances, num_users, num_items,k=5)\n",
    "results_patk = cv_patk.run(algorithm_instances, num_users, num_items,k=5)\n",
    "results_ratk = cv_ratk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average and CI of RMSE for popularity is : [3.1590928909890112, [3.139292746995387, 3.1788930349826354]]\n",
      "The average and CI of RMSE for useraverage is : [1.0437176561595025, [1.0289303496379316, 1.0585049626810734]]\n",
      "The average and CI of RMSE for item-cosine is : [1.020082900106248, [1.0068242686250732, 1.0333415315874226]]\n",
      "The average and CI of RMSE for user-cosine is : [1.0173541216605808, [1.009013080226148, 1.0256951630950135]]\n"
     ]
    }
   ],
   "source": [
    "for k,v in results_RMSE.items():\n",
    "    print(\"The average and CI of RMSE for {} is : [{}, {}]\".format(k, results_RMSE[k][1], results_RMSE[k][2:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average and CI of patk for popularity is : [0.5505832449628855, [0.40544114481568705, 0.6957253451100839]]\n",
      "The average and CI of patk for useraverage is : [0.4736373276776259, [0.3419993013451059, 0.6052753540101459]]\n",
      "The average and CI of patk for item-cosine is : [0.5322163308589621, [0.3837005215009889, 0.6807321402169354]]\n",
      "The average and CI of patk for user-cosine is : [0.5558430540827157, [0.40959849499983714, 0.7020876131655943]]\n"
     ]
    }
   ],
   "source": [
    "for k,v in results_patk.items():\n",
    "    print(\"The average and CI of patk for {} is : [{}, {}]\".format(k, results_patk[k][1], results_patk[k][2:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average and CI of ratk for popularity is : [0.4840758878843688, [0.3671373629798323, 0.6010144127889052]]\n",
      "The average and CI of ratk for useraverage is : [0.44132320502242983, [0.32931026359142457, 0.5533361464534351]]\n",
      "The average and CI of ratk for item-cosine is : [0.4749711148590666, [0.35357317503649865, 0.5963690546816346]]\n",
      "The average and CI of ratk for user-cosine is : [0.4862687235536437, [0.3694473610987218, 0.6030900860085656]]\n"
     ]
    }
   ],
   "source": [
    "for k,v in results_ratk.items():\n",
    "    print(\"The average and CI of ratk for {} is : [{}, {}]\".format(k, results_ratk[k][1], results_ratk[k][2:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can know from the results that popularity cannot be evaluated with RMSE because the popularity is the fraction of people who have rated the movie that liked the movie and it falls in the range of (0,1). It does not make sense to compare two different things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "For all of RMSE, P@K, and R@K the best algorithm is user-cosine.First, popularity based recommendations only recommend the most popular items but not recommend items based on the user's likes. User average recommendations are also a very basic method that simply averages the user's ratings for other items. Compared with those baseline algorithms, collaborative filtering is better. The average number of ratings per user is larger than the average number of ratings per item so for item based collaborative filtering it is more difficult to find similar items than user based which would reduce accuracy of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\n",
    "\n",
    "Better RMSE scores on data indicate better generalization of the learned model and often better rankings. Unlike ranking, which focuses more on high-scoring items, RMSE places equal emphasis on high and low ratings. So ranking metrics do not consider the error of low ratings so good ranking metrics do not imply good performance on RMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>movieTitle</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>videoReleaseDate</th>\n",
       "      <th>IMDbURL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>childrens</th>\n",
       "      <th>...</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>filmNoir</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sciFi</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID         movieTitle  releaseDate  videoReleaseDate  \\\n",
       "0        1   Toy Story (1995)  01-Jan-1995               NaN   \n",
       "1        2   GoldenEye (1995)  01-Jan-1995               NaN   \n",
       "2        3  Four Rooms (1995)  01-Jan-1995               NaN   \n",
       "3        4  Get Shorty (1995)  01-Jan-1995               NaN   \n",
       "4        5     Copycat (1995)  01-Jan-1995               NaN   \n",
       "\n",
       "                                             IMDbURL  unknown  action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   adventure  animation  childrens   ...     fantasy  filmNoir  horror  \\\n",
       "0          0          1          1   ...           0         0       0   \n",
       "1          1          0          0   ...           0         0       0   \n",
       "2          0          0          0   ...           0         0       0   \n",
       "3          0          0          0   ...           0         0       0   \n",
       "4          0          0          0   ...           0         0       0   \n",
       "\n",
       "   musical  mystery  romance  sciFi  thriller  war  western  \n",
       "0        0        0        0      0         0    0        0  \n",
       "1        0        0        0      0         1    0        0  \n",
       "2        0        0        0      0         1    0        0  \n",
       "3        0        0        0      0         0    0        0  \n",
       "4        0        0        0      0         1    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
    "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
    "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
    "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
    "\n",
    "moviesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maybe, Maybe Not (Bewegte Mann, Der) (1994)', 'Breaking the Waves (1996)', 'Savage Nights (Nuits fauves, Les) (1992)', 'Chungking Express (1994)', \"I Can't Sleep (J'ai pas sommeil) (1994)\"]\n",
      "['Kingpin (1996)', 'Cable Guy, The (1996)', 'Nutty Professor, The (1996)', 'Happy Gilmore (1996)', 'Beverly Hills Ninja (1997)']\n",
      "['Brazil (1985)', 'Apocalypse Now (1979)', 'Graduate, The (1967)', 'Blade Runner (1982)', 'Raiders of the Lost Ark (1981)']\n"
     ]
    }
   ],
   "source": [
    "trainUserItemMatrix = dataPreprocessor(rating_df, num_users, num_items)\n",
    "trainUserItemMatrix = trainUserItemMatrix.T\n",
    "itemSimilarity = 1 - pairwise_distances(trainUserItemMatrix, metric='cosine')\n",
    "for i in [6,369,135]:\n",
    "    print(list(map(lambda x:moviesDF.iloc[x][1],itemSimilarity[i-1].argsort()[-6:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pick '2001: A Space Odyssey','Black Sheep,''Yao a yao yao dao waipo qiao'. The mechanism of item based collaborative filtering is if two items are rated by alomost the same group of people, the two items are more likely to be in the same class like they are both comedies or animations. For the above three movies, we can find out top 5 similar movies for each of them are more likely to be the same type of movies like mystery or drama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 [GRAD ONLY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([331., 152.,  75.,  68.,  53.,  52.,  35.,  35.,  29.,  24.,  17.,\n",
       "         18.,  12.,   9.,   7.,   8.,   5.,   3.,   1.,   1.,   3.,   1.,\n",
       "          1.,   0.,   0.,   0.,   1.,   0.,   1.,   0.,   1.]),\n",
       " array([ 20.        ,  43.12903226,  66.25806452,  89.38709677,\n",
       "        112.51612903, 135.64516129, 158.77419355, 181.90322581,\n",
       "        205.03225806, 228.16129032, 251.29032258, 274.41935484,\n",
       "        297.5483871 , 320.67741935, 343.80645161, 366.93548387,\n",
       "        390.06451613, 413.19354839, 436.32258065, 459.4516129 ,\n",
       "        482.58064516, 505.70967742, 528.83870968, 551.96774194,\n",
       "        575.09677419, 598.22580645, 621.35483871, 644.48387097,\n",
       "        667.61290323, 690.74193548, 713.87096774, 737.        ]),\n",
       " <a list of 31 Patch objects>)"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEQRJREFUeJzt3X+s3XV9x/HnaxTxFxOQC+nauqLrjJjMQhqGYTFMnD9wEU1kKVm0MSw1GyaSmWzFJVOTkeAyxZhsOBxMXJQf88dokE0ZYoxLBC+I/KqMop1cW2n9BTozM/C9P87n6l29vef03nN7z/3wfCQn5/v9nM8559We29f53s/50VQVkqR+/cpKB5AkLS+LXpI6Z9FLUucseknqnEUvSZ2z6CWpcxa9JHXOopekzln0ktS5NSsdAODEE0+sjRs3rnQMSVpV7rzzzu9W1dSweRNR9Bs3bmR6enqlY0jSqpLkv0aZ59KNJHXOopekzln0ktQ5i16SOmfRS1LnLHpJ6pxFL0mds+glqXMWvSR1biI+GbsUG3d8ZqR5ey577TInkaTJ5BG9JHXOopekzln0ktQ5i16SOmfRS1LnLHpJ6pxFL0mds+glqXMWvSR1zqKXpM5Z9JLUOYtekjpn0UtS5yx6Serc0KJP8vQkdyT5WpL7k7ynjZ+S5PYkDyW5PsnT2vgxbX93u3zj8v4RJEkLGeWI/qfAy6vqJcBm4NVJzgTeC1xeVZuAHwAXtvkXAj+oqt8ALm/zJEkrZGjR18CP2+7R7VTAy4FPtPFrgNe37fPaPu3yc5JkbIklSYdlpDX6JEcluRvYD9wCPAz8sKqeaFNmgHVtex3wCEC7/DHgueMMLUka3UhFX1VPVtVmYD1wBvCi+aa18/mO3uvggSTbk0wnmT5w4MCoeSVJh+mw3nVTVT8EvgCcCRyXZPb/nF0P7G3bM8AGgHb5c4Dvz3NbV1bVlqraMjU1tbj0kqShRnnXzVSS49r2M4BXALuA24A3tmnbgBvb9s62T7v881X1S0f0kqQjY83wKawFrklyFIMnhhuq6qYkDwDXJfkr4KvAVW3+VcA/JdnN4Eh+6zLkliSNaGjRV9U9wGnzjH+DwXr9weP/A5w/lnSSpCXzk7GS1DmLXpI6Z9FLUucseknqnEUvSZ2z6CWpcxa9JHXOopekzln0ktQ5i16SOmfRS1LnLHpJ6pxFL0mds+glqXMWvSR1zqKXpM5Z9JLUOYtekjpn0UtS5yx6SeqcRS9JnbPoJalzFr0kdW5o0SfZkOS2JLuS3J/k7W383Um+neTudjp3znUuSbI7yYNJXrWcfwBJ0sLWjDDnCeAdVXVXkmOBO5Pc0i67vKr+Zu7kJKcCW4EXA78G/HuS36yqJ8cZXJI0mqFH9FW1r6ruats/AnYB6xa4ynnAdVX106r6JrAbOGMcYSVJh++w1uiTbAROA25vQ29Lck+Sq5Mc38bWAY/MudoM8zwxJNmeZDrJ9IEDBw47uCRpNCMXfZJnA58ELq6qx4ErgBcAm4F9wPtmp85z9fqlgaorq2pLVW2Zmpo67OCSpNGMVPRJjmZQ8h+rqk8BVNWjVfVkVf0M+DC/WJ6ZATbMufp6YO/4IkuSDsco77oJcBWwq6reP2d87ZxpbwDua9s7ga1JjklyCrAJuGN8kSVJh2OUd92cBbwJuDfJ3W3sncAFSTYzWJbZA7wVoKruT3ID8ACDd+xc5DtuJGnlDC36qvoS86+737zAdS4FLl1CLknSmPjJWEnqnEUvSZ2z6CWpcxa9JHXOopekzln0ktQ5i16SOmfRS1LnLHpJ6pxFL0mds+glqXMWvSR1zqKXpM5Z9JLUOYtekjpn0UtS5yx6SeqcRS9JnbPoJalzFr0kdc6il6TOWfSS1LmhRZ9kQ5LbkuxKcn+St7fxE5LckuShdn58G0+SDybZneSeJKcv9x9CknRooxzRPwG8o6peBJwJXJTkVGAHcGtVbQJubfsArwE2tdN24Iqxp5YkjWxo0VfVvqq6q23/CNgFrAPOA65p064BXt+2zwM+WgNfBo5LsnbsySVJIzmsNfokG4HTgNuBk6tqHwyeDICT2rR1wCNzrjbTxiRJK2Dkok/ybOCTwMVV9fhCU+cZq3lub3uS6STTBw4cGDWGJOkwjVT0SY5mUPIfq6pPteFHZ5dk2vn+Nj4DbJhz9fXA3oNvs6qurKotVbVlampqsfklSUOM8q6bAFcBu6rq/XMu2glsa9vbgBvnjL+5vfvmTOCx2SUeSdKRt2aEOWcBbwLuTXJ3G3sncBlwQ5ILgW8B57fLbgbOBXYDPwHeMtbEkqTDMrToq+pLzL/uDnDOPPMLuGiJuSRJY+InYyWpcxa9JHXOopekzln0ktQ5i16SOmfRS1LnLHpJ6pxFL0mds+glqXMWvSR1zqKXpM5Z9JLUOYtekjpn0UtS5yx6SeqcRS9JnbPoJalzFr0kdc6il6TOWfSS1DmLXpI6Z9FLUueGFn2Sq5PsT3LfnLF3J/l2krvb6dw5l12SZHeSB5O8armCS5JGM8oR/UeAV88zfnlVbW6nmwGSnApsBV7crvN3SY4aV1hJ0uEbWvRV9UXg+yPe3nnAdVX106r6JrAbOGMJ+SRJS7RmCdd9W5I3A9PAO6rqB8A64Mtz5sy0sRW3ccdnRpq357LXLnMSSTqyFvti7BXAC4DNwD7gfW0888yt+W4gyfYk00mmDxw4sMgYkqRhFlX0VfVoVT1ZVT8DPswvlmdmgA1zpq4H9h7iNq6sqi1VtWVqamoxMSRJI1hU0SdZO2f3DcDsO3J2AluTHJPkFGATcMfSIkqSlmLoGn2Sa4GzgROTzADvAs5OspnBsswe4K0AVXV/khuAB4AngIuq6snliS5JGsXQoq+qC+YZvmqB+ZcCly4llCRpfPxkrCR1zqKXpM5Z9JLUOYtekjpn0UtS5yx6SeqcRS9JnbPoJalzFr0kdc6il6TOWfSS1DmLXpI6Z9FLUucseknqnEUvSZ2z6CWpcxa9JHXOopekzln0ktQ5i16SOmfRS1LnLHpJ6pxFL0mdG1r0Sa5Osj/JfXPGTkhyS5KH2vnxbTxJPphkd5J7kpy+nOElScONckT/EeDVB43tAG6tqk3ArW0f4DXApnbaDlwxnpiSpMUaWvRV9UXg+wcNnwdc07avAV4/Z/yjNfBl4Lgka8cVVpJ0+Ba7Rn9yVe0DaOcntfF1wCNz5s20sV+SZHuS6STTBw4cWGQMSdIw434xNvOM1XwTq+rKqtpSVVumpqbGHEOSNGuxRf/o7JJMO9/fxmeADXPmrQf2Lj6eJGmpFlv0O4FtbXsbcOOc8Te3d9+cCTw2u8QjSVoZa4ZNSHItcDZwYpIZ4F3AZcANSS4EvgWc36bfDJwL7AZ+ArxlGTJLkg7D0KKvqgsOcdE588wt4KKlhpIkjY+fjJWkzln0ktQ5i16SOmfRS1LnLHpJ6pxFL0mds+glqXMWvSR1zqKXpM5Z9JLUuaFfgfBUs3HHZ0aat+ey1y5zEkkaD4/oJalzFr0kdc6il6TOuUa/SK7lS1otPKKXpM5Z9JLUOYtekjpn0UtS5yx6SeqcRS9JnbPoJalzS3offZI9wI+AJ4EnqmpLkhOA64GNwB7gD6rqB0uLKUlarHEc0f9uVW2uqi1tfwdwa1VtAm5t+5KkFbIcn4w9Dzi7bV8DfAH482W4n1Vh1E/QjsJP2UpajKUe0RfwuSR3Jtnexk6uqn0A7fykJd6HJGkJlnpEf1ZV7U1yEnBLkq+PesX2xLAd4HnPe94SY0iSDmVJR/RVtbed7wc+DZwBPJpkLUA733+I615ZVVuqasvU1NRSYkiSFrDook/yrCTHzm4DrwTuA3YC29q0bcCNSw0pSVq8pSzdnAx8Osns7Xy8qv4tyVeAG5JcCHwLOH/pMSVJi7Xooq+qbwAvmWf8e8A5SwklSRofPxkrSZ2z6CWpcxa9JHXOopekzvmfg68i4/w6BfArFaSnCo/oJalzFr0kdc6il6TOuUb/FDbqmr9r+dLq5hG9JHXOopekzrl0o6Fc4pFWN4/oJalzFr0kdc6il6TOuUavsRnnVzS43i+Nj0f0ktQ5i16SOufSjSaSb+mUxscjeknqnEf0WtU88peGs+j1lOB/2qKnsmVbukny6iQPJtmdZMdy3Y8kaWHLckSf5Cjgb4HfA2aAryTZWVUPLMf9SUfaKL8heNSvSbFcSzdnALur6hsASa4DzgMsej1lrNTrB75uoYMtV9GvAx6Zsz8D/PYy3Ze0qo379YOVuN+VetIY55PauJ8gJ+kJd7mKPvOM1f+bkGwHtrfdHyd58BC3dSLw3TFmWy6rJSesnqyrJSesnqzLkjPvHfctAmPMOs5889zWknIuMduvjzJpuYp+BtgwZ389sHfuhKq6Erhy2A0lma6qLeONN36rJSesnqyrJSesnqyrJSesnqyrIedyvevmK8CmJKckeRqwFdi5TPclSVrAshzRV9UTSd4GfBY4Cri6qu5fjvuSJC1s2T4wVVU3AzeP4aaGLu9MiNWSE1ZP1tWSE1ZP1tWSE1ZP1onPmaoaPkuStGr5pWaS1LmJLfpJ+wqFJFcn2Z/kvjljJyS5JclD7fz4Np4kH2zZ70ly+hHMuSHJbUl2Jbk/ydsnOOvTk9yR5Gst63va+ClJbm9Zr28v6JPkmLa/u12+8Uhlbfd/VJKvJrlpwnPuSXJvkruTTLexSXz8j0vyiSRfbz+vL520nEle2P4eZ0+PJ7l40nIOVVUTd2LwAu7DwPOBpwFfA05d4UwvA04H7psz9tfAjra9A3hv2z4X+FcGnyc4E7j9COZcC5zeto8F/hM4dUKzBnh22z4auL1luAHY2sY/BPxx2/4T4ENteytw/RH+GfhT4OPATW1/UnPuAU48aGwSH/9rgD9q208DjpvEnHPyHgV8h8F71yc257zZVzrAIf5CXwp8ds7+JcAlE5Br40FF/yCwtm2vBR5s238PXDDfvBXIfCOD7xya6KzAM4G7GHyC+rvAmoN/Fhi8i+ulbXtNm5cjlG89cCvwcuCm9g954nK2+5yv6Cfq8Qd+FfjmwX8vk5bzoGyvBP5j0nPOd5rUpZv5vkJh3QplWcjJVbUPoJ2f1MYnIn9bMjiNwZHyRGZtyyF3A/uBWxj8JvfDqnpinjw/z9oufwx47hGK+gHgz4Cftf3nTmhOGHwK/XNJ7szgE+gweY//84EDwD+25bB/SPKsCcw511bg2rY9yTl/yaQW/dCvUJhwK54/ybOBTwIXV9XjC02dZ+yIZa2qJ6tqM4Mj5jOAFy2QZ0WyJvl9YH9V3Tl3eIEsK/34n1VVpwOvAS5K8rIF5q5U1jUMlkKvqKrTgP9msARyKCv6d9pef3kd8M/Dps4ztuLdNalFP/QrFCbEo0nWArTz/W18RfMnOZpByX+sqj41yVlnVdUPgS8wWNc8LsnsZzzm5vl51nb5c4DvH4F4ZwGvS7IHuI7B8s0HJjAnAFW1t53vBz7N4Al00h7/GWCmqm5v+59gUPyTlnPWa4C7qurRtj+pOec1qUW/Wr5CYSewrW1vY7AePjv+5vYK/JnAY7O/5i23JAGuAnZV1fsnPOtUkuPa9jOAVwC7gNuANx4i6+yf4Y3A56sthC6nqrqkqtZX1UYGP4ufr6o/nLScAEmeleTY2W0G68r3MWGPf1V9B3gkyQvb0DkMvsZ8onLOcQG/WLaZzTOJOee30i8SLPDCx7kM3jHyMPAXE5DnWmAf8L8MnrUvZLDueivwUDs/oc0Ng/945WHgXmDLEcz5Owx+VbwHuLudzp3QrL8FfLVlvQ/4yzb+fOAOYDeDX5WPaeNPb/u72+XPX4Gfg7P5xbtuJi5ny/S1drp/9t/OhD7+m4Hp9vj/C3D8hOZ8JvA94DlzxiYu50InPxkrSZ2b1KUbSdKYWPSS1DmLXpI6Z9FLUucseknqnEUvSZ2z6CWpcxa9JHXu/wAKUfzj2GgOLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "UserItemMatrix = dataPreprocessor(rating_df, num_users, num_items)\n",
    "data = (UserItemMatrix!=0).sum(1)\n",
    "plt.hist(data,bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "above_userID = [i+1 for i,val in enumerate(data.tolist()) if val >= 100]\n",
    "below_userID = [i+1 for i,val in enumerate(data.tolist()) if val < 100]\n",
    "above_threshold = rating_df[rating_df['userID'].isin(above_userID)]\n",
    "below_threshold = rating_df[rating_df['userID'].isin(below_userID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q6CrossValidation(object):\n",
    "    def __init__(self, metric, criteria, cdata_path=MOVIELENS_DIR):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(MOVIELENS_DIR,criteria)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def _getData(data_path,criteria):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            test_set = test_set[test_set['userID'].isin(criteria)]\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "15082it [00:08, 1718.81it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "15115it [00:08, 1741.52it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "14748it [00:08, 1760.82it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "14802it [00:08, 1761.25it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "14775it [00:08, 1758.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15082it [00:08, 1830.33it/s]\n",
      "15115it [00:08, 1813.33it/s]\n",
      "14748it [00:08, 1800.43it/s]\n",
      "14802it [00:08, 1767.21it/s]\n",
      "14775it [00:08, 1791.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "4918it [00:02, 1897.19it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "4885it [00:02, 1860.57it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "5252it [00:02, 1842.17it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "5198it [00:02, 1860.12it/s]\n",
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "5225it [00:02, 1869.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4918it [00:02, 1795.31it/s]\n",
      "4885it [00:03, 1493.33it/s]\n",
      "5252it [00:04, 1133.27it/s]\n",
      "5198it [00:04, 1218.67it/s]\n",
      "5225it [00:03, 1367.38it/s]\n"
     ]
    }
   ],
   "source": [
    "algorithm_instances = [item_cosine_recsys, \n",
    "                       user_cosine_recsys]\n",
    "cv_RMSE_above = Q6CrossValidation('RMSE',above_userID)\n",
    "cv_RMSE_below = Q6CrossValidation('RMSE',below_userID)\n",
    "above_results = cv_RMSE_above.run(algorithm_instances, num_users, num_items,k=5)\n",
    "below_results = cv_RMSE_below.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average and CI of RMSE for item-cosine is : [1.0157058792368447, [0.9970328517019386, 1.0343789067717508]]\n",
      "The average and CI of RMSE for user-cosine is : [1.0099437276866055, [0.9998560554715185, 1.0200313999016926]]\n"
     ]
    }
   ],
   "source": [
    "for k,v in above_results.items():\n",
    "    print(\"The average and CI of RMSE for {} is : [{}, {}]\".format(k, above_results[k][1], above_results[k][2:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average and CI of RMSE for item-cosine is : [1.0323071802224322, [1.0216936031404484, 1.042920757304416]]\n",
      "The average and CI of RMSE for user-cosine is : [1.0387105824533651, [1.0296960894624052, 1.047725075444325]]\n"
     ]
    }
   ],
   "source": [
    "for k,v in below_results.items():\n",
    "    print(\"The average and CI of RMSE for {} is : [{}, {}]\".format(k, below_results[k][1], below_results[k][2:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both user based and item based filtering, the performance are better with users whose the number of ratings is above the threshold 100. Say that new users who do not have any ratings yet, it is hard to use similarity (collaborative filtering) for them so if users only have rated a few items, the predictions using similarity for them are not that accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for validation only\n",
    "ROW_NUM = 943\n",
    "COL_NUM = 1682\n",
    "RATING_COL = 'rating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
    "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
    "    try:\n",
    "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    except:\n",
    "        print('dataPreprocessor function has error')\n",
    "        return\n",
    "    try:\n",
    "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = validateDataPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    popularity_recsys = BaseLineRecSys('popularity')\n",
    "    try:\n",
    "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except Exception as e:        \n",
    "        print('popularity function has error')\n",
    "        print(e)\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = popularity_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "validatePopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Average Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    useraverage_recsys = BaseLineRecSys('average_user_rating')\n",
    "    try:\n",
    "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except:\n",
    "        print('useraverage function has error')\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = useraverage_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "validatePopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similary Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateEuclidean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Similarity Function (test somethingelse function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateCustomizedSim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-User Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please make sure you are using given yml file.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:78: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "validateUUSimBasedRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-Item Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please make sure you are using given yml file.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\3.5.2\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "validateIISimBasedRecSys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
